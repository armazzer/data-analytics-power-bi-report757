{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_credentials():\n",
    "    '''This function reads the credentials file, returning a dictionary'''\n",
    "    with open(\"creds.yaml\", \"r\") as file:\n",
    "        credentials = yaml.safe_load(file)\n",
    "        return credentials\n",
    "\n",
    "credentials = load_credentials()\n",
    "\n",
    "# Create a new directory to save results in.\n",
    "query_results_dir = \"tables_columns_auto\"\n",
    "Path(query_results_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "class DatabaseConnector:\n",
    "    '''This class is used to connect to the database, extract the required data, and save the data in csv files.\n",
    "        Attributes:\n",
    "            credentials (dict): a dictionary of credentials required to connect to the database.\n",
    "            tables_df (dataframe): a dataframe that is initially empty, and will be updated with data extracted from the RDS database.\n",
    "            tables_list (list): a list that is initially empty, and will be updated with the names of the tables in tables_df.'''\n",
    "    def __init__(self, credentials):\n",
    "        self.credentials = credentials\n",
    "        self.tables_df = pd.DataFrame()\n",
    "        self.tables_list = []\n",
    "\n",
    "    def get_tables(self, conn):\n",
    "        '''This method reads data based on a query, given as argument to the read_sql function, via the connection established in the get_data method.\n",
    "        The class attribute tables_df is then updated with the resulting dataframe. The dataframe is also saved to a csv file.\n",
    "        Additionally, tables_df is converted to a list and used to update the class attribute tables_list'''\n",
    "        tables_query = '''\n",
    "            SELECT\n",
    "                table_name\n",
    "            FROM \n",
    "                INFORMATION_SCHEMA.TABLES\n",
    "            WHERE \n",
    "                table_schema = 'public'\n",
    "            AND\n",
    "                table_type = 'BASE TABLE'\n",
    "            ORDER BY\n",
    "                table_name ASC    \n",
    "            '''\n",
    "        \n",
    "        table_names = pd.read_sql(tables_query, conn)\n",
    "        self.tables_df = table_names\n",
    "\n",
    "        # Save DataFrame to CSV file in a subdirectory\n",
    "        file_name = Path(query_results_dir) / \"tables_list.csv\"\n",
    "        table_names.to_csv(file_name, index=False)\n",
    "\n",
    "        # Create a list of table names from tables_df, based on the column 'table_name'\n",
    "        tables_list = self.tables_df['table_name'].tolist()\n",
    "        self.tables_list = tables_list\n",
    "\n",
    "    def get_columns(self, tables_list, conn):\n",
    "        '''This method iterates through tables_list. \n",
    "        For each item the method reads data based on a query given as an argument to the read_sql function, \n",
    "        via the connection established in the get_data method, and assigns the result to the columns_df variable. \n",
    "        The resulting dataframe is then saved as a csv file'''\n",
    "        for table in tables_list:\n",
    "            columns_query = f'''\n",
    "                SELECT\n",
    "                    column_name\n",
    "                FROM \n",
    "                    INFORMATION_SCHEMA.COLUMNS\n",
    "                WHERE \n",
    "                    table_schema = 'public'\n",
    "                AND\n",
    "                    table_name = '{table}'\n",
    "                '''\n",
    "            \n",
    "            columns_df = pd.read_sql(columns_query, conn)\n",
    "\n",
    "            # Save DataFrame to CSV file in a subdirectory\n",
    "            file_name = Path(query_results_dir) / f\"{table}_columns.csv\"\n",
    "            columns_df.to_csv(file_name, index=False)\n",
    "\n",
    "    def get_data(self):\n",
    "        '''This method creates an engine to establish a connection to the database. \n",
    "        The get_tables and get_columns methods then run as sub-methods.''' \n",
    "        DATABASE_TYPE = self.credentials[\"DATABASE_TYPE\"]\n",
    "        DBAPI = self.credentials[\"DBAPI\"]\n",
    "        HOST = self.credentials[\"HOST\"]\n",
    "        USER = self.credentials[\"USER\"]\n",
    "        PASSWORD = self.credentials[\"PASSWORD\"]\n",
    "        DATABASE = self.credentials[\"DATABASE\"]\n",
    "        PORT = self.credentials[\"PORT\"]\n",
    "        \n",
    "        engine = create_engine(f\"{DATABASE_TYPE}+{DBAPI}://{USER}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}\")\n",
    "        with engine.execution_options(isolation_level='AUTOCOMMIT').connect() as conn:\n",
    "            self.get_tables(conn)\n",
    "        \n",
    "        with engine.execution_options(isolation_level='AUTOCOMMIT').connect() as conn:\n",
    "            self.get_columns(self.tables_list, conn)\n",
    "\n",
    "\n",
    "\n",
    "connector = DatabaseConnector(credentials)\n",
    "connector.get_data()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
